{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14046335,"sourceType":"datasetVersion","datasetId":8941981}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# INF506 Data Analysis Methods - Term Project\n# Athens Housing Market Data Cleaning\n# Data Source: spitogatos.gr\n# Date: December 2025\n\n# ============================================================================\n# CELL 1: Import Required Libraries\n# ============================================================================\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set display options for better readability\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\nprint(\"Libraries imported successfully!\")\nprint(f\"Pandas version: {pd.__version__}\")\nprint(f\"NumPy version: {np.__version__}\")\n\n# ============================================================================\n# CELL 2: Load Raw Data\n# ============================================================================\n# Load the raw scraped data from CSV\ndf_raw = pd.read_csv('athens_complete_house_data_raw.csv')\n\nprint(\"=\"*80)\nprint(\"RAW DATA LOADED\")\nprint(\"=\"*80)\nprint(f\"\\nDataset Shape: {df_raw.shape}\")\nprint(f\"Total Records: {df_raw.shape[0]}\")\nprint(f\"Total Features: {df_raw.shape[1]}\")\nprint(\"\\nColumn Names:\")\nprint(df_raw.columns.tolist())\n\n# ============================================================================\n# CELL 3: Initial Data Overview\n# ============================================================================\nprint(\"=\"*80)\nprint(\"INITIAL DATA OVERVIEW\")\nprint(\"=\"*80)\n\n# Display first few rows\nprint(\"\\nFirst 5 rows of raw data:\")\nprint(df_raw.head())\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\\nData Types:\")\nprint(df_raw.dtypes)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\\nBasic Information:\")\nprint(df_raw.info())\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\\nBasic Statistics:\")\nprint(df_raw.describe(include='all'))\n\n# ============================================================================\n# CELL 4: Data Quality Assessment - Missing Values\n# ============================================================================\nprint(\"=\"*80)\nprint(\"DATA QUALITY ASSESSMENT - MISSING VALUES\")\nprint(\"=\"*80)\n\n# Check for missing values\nmissing_data = pd.DataFrame({\n    'Column': df_raw.columns,\n    'Missing_Count': df_raw.isnull().sum(),\n    'Missing_Percentage': (df_raw.isnull().sum() / len(df_raw) * 100).round(2)\n})\nmissing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n\nprint(\"\\nMissing Values Summary:\")\nif len(missing_data) > 0:\n    print(missing_data.to_string(index=False))\nelse:\n    print(\"No missing values found!\")\n\n# Visualize missing values\nplt.figure(figsize=(10, 6))\nmissing_counts = df_raw.isnull().sum()\nmissing_counts[missing_counts > 0].plot(kind='bar', color='coral')\nplt.title('Missing Values by Column', fontsize=14, fontweight='bold')\nplt.xlabel('Columns', fontsize=12)\nplt.ylabel('Number of Missing Values', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# CELL 5: Create Working Copy and Check for Duplicates\n# ============================================================================\nprint(\"=\"*80)\nprint(\"CREATING WORKING COPY & CHECKING DUPLICATES\")\nprint(\"=\"*80)\n\n# Create a copy for cleaning\ndf = df_raw.copy()\n\n# Check for duplicate rows\nprint(f\"\\nTotal duplicate rows: {df.duplicated().sum()}\")\n\n# Check for duplicates based on URL (unique identifier)\nif 'url' in df.columns:\n    duplicate_urls = df.duplicated(subset=['url'], keep=False).sum()\n    print(f\"Duplicate URLs: {duplicate_urls}\")\n    \n    if duplicate_urls > 0:\n        print(\"\\nRemoving duplicate URLs (keeping first occurrence)...\")\n        df = df.drop_duplicates(subset=['url'], keep='first')\n        print(f\"Rows after removing URL duplicates: {len(df)}\")\n\n# Check for exact duplicate rows\nexact_duplicates = df.duplicated().sum()\nif exact_duplicates > 0:\n    print(f\"\\nExact duplicate rows found: {exact_duplicates}\")\n    print(\"Removing exact duplicates...\")\n    df = df.drop_duplicates(keep='first')\n    print(f\"Rows after removing exact duplicates: {len(df)}\")\n\nprint(f\"\\nFinal dataset shape after duplicate removal: {df.shape}\")\n\n# ============================================================================\n# CELL 6: Clean Property Type Column\n# ============================================================================\nprint(\"=\"*80)\nprint(\"CLEANING: PROPERTY TYPE\")\nprint(\"=\"*80)\n\nprint(\"\\nOriginal property_type distribution:\")\nprint(df['property_type'].value_counts())\n\n# Standardize property types\ndf['property_type'] = df['property_type'].str.strip()\n\n# Check for any unusual values\nprint(\"\\nUnique property types after stripping:\")\nprint(df['property_type'].unique())\n\nprint(f\"\\nMissing values in property_type: {df['property_type'].isnull().sum()}\")\n\n# ============================================================================\n# CELL 7: Clean Size Column (Extract Numeric Values)\n# ============================================================================\nprint(\"=\"*80)\nprint(\"CLEANING: SIZE\")\nprint(\"=\"*80)\n\nprint(\"\\nOriginal size column samples:\")\nprint(df['size'].head(10))\n\n# Function to extract numeric value from size\ndef clean_size(size_str):\n    if pd.isna(size_str):\n        return np.nan\n    # Extract numeric value using regex\n    match = re.search(r'(\\d+(?:\\.\\d+)?)', str(size_str))\n    if match:\n        return float(match.group(1))\n    return np.nan\n\n# Apply cleaning\ndf['size_sqm'] = df['size'].apply(clean_size)\n\nprint(\"\\nSize statistics after cleaning:\")\nprint(df['size_sqm'].describe())\n\nprint(f\"\\nMissing values in size_sqm: {df['size_sqm'].isnull().sum()}\")\n\n# Check for unrealistic values\nprint(\"\\nChecking for outliers in size:\")\nprint(f\"Minimum size: {df['size_sqm'].min()} m²\")\nprint(f\"Maximum size: {df['size_sqm'].max()} m²\")\nprint(f\"Properties with size < 10 m²: {(df['size_sqm'] < 10).sum()}\")\nprint(f\"Properties with size > 1000 m²: {(df['size_sqm'] > 1000).sum()}\")\n\n# ============================================================================\n# CELL 8: Clean Price Column (Extract Numeric Values)\n# ============================================================================\nprint(\"=\"*80)\nprint(\"CLEANING: PRICE\")\nprint(\"=\"*80)\n\nprint(\"\\nOriginal price column samples:\")\nprint(df['price'].head(10))\n\n# Function to extract numeric value from price\ndef clean_price(price_str):\n    if pd.isna(price_str):\n        return np.nan\n    # Remove €, commas, and spaces, then extract number\n    price_clean = str(price_str).replace('€', '').replace(',', '').replace(' ', '')\n    match = re.search(r'(\\d+(?:\\.\\d+)?)', price_clean)\n    if match:\n        return float(match.group(1))\n    return np.nan\n\n# Apply cleaning\ndf['price_eur'] = df['price'].apply(clean_price)\n\nprint(\"\\nPrice statistics after cleaning:\")\nprint(df['price_eur'].describe())\n\nprint(f\"\\nMissing values in price_eur: {df['price_eur'].isnull().sum()}\")\n\n# Check for unrealistic values\nprint(\"\\nChecking for outliers in price:\")\nprint(f\"Minimum price: €{df['price_eur'].min():,.0f}\")\nprint(f\"Maximum price: €{df['price_eur'].max():,.0f}\")\nprint(f\"Properties with price < €10,000: {(df['price_eur'] < 10000).sum()}\")\nprint(f\"Properties with price > €5,000,000: {(df['price_eur'] > 5000000).sum()}\")\n\n# ============================================================================\n# CELL 9: Clean Bedrooms Column\n# ============================================================================\nprint(\"=\"*80)\nprint(\"CLEANING: BEDROOMS\")\nprint(\"=\"*80)\n\nprint(\"\\nBedrooms statistics:\")\nprint(df['bedrooms'].describe())\n\nprint(f\"\\nMissing values in bedrooms: {df['bedrooms'].isnull().sum()}\")\n\n# Check distribution\nprint(\"\\nBedrooms distribution:\")\nprint(df['bedrooms'].value_counts().sort_index())\n\n# Check for unrealistic values\nprint(f\"\\nProperties with 0 bedrooms: {(df['bedrooms'] == 0).sum()}\")\nprint(f\"Properties with > 10 bedrooms: {(df['bedrooms'] > 10).sum()}\")\n\n# ============================================================================\n# CELL 10: Clean Bathrooms Column\n# ============================================================================\nprint(\"=\"*80)\nprint(\"CLEANING: BATHROOMS\")\nprint(\"=\"*80)\n\nprint(\"\\nBathrooms statistics:\")\nprint(df['bathrooms'].describe())\n\nprint(f\"\\nMissing values in bathrooms: {df['bathrooms'].isnull().sum()}\")\n\n# Check distribution\nprint(\"\\nBathrooms distribution:\")\nprint(df['bathrooms'].value_counts().sort_index())\n\n# Check for unrealistic values\nprint(f\"\\nProperties with 0 bathrooms: {(df['bathrooms'] == 0).sum()}\")\nprint(f\"Properties with > 10 bathrooms: {(df['bathrooms'] > 10).sum()}\")\n\n# ============================================================================\n# CELL 11: Clean Floor Column\n# ============================================================================\nprint(\"=\"*80)\nprint(\"CLEANING: FLOOR\")\nprint(\"=\"*80)\n\nprint(\"\\nOriginal floor column samples:\")\nprint(df['floor'].value_counts().head(20))\n\n# Function to clean and standardize floor information\ndef clean_floor(floor_str):\n    if pd.isna(floor_str):\n        return np.nan\n    \n    floor_str = str(floor_str).strip().lower()\n    \n    # Handle special cases\n    if floor_str in ['g', 'ground', 'ground floor']:\n        return 0\n    if floor_str in ['b', 'basement']:\n        return -1\n    if floor_str in ['semi-basement', 'semi basement']:\n        return -0.5\n    if floor_str in ['mezzanine']:\n        return 0.5\n    \n    # Extract numeric value (remove st, nd, rd, th, \\nth, etc.)\n    floor_clean = re.sub(r'\\\\n[a-z]{2}', '', floor_str)\n    floor_clean = re.sub(r'(st|nd|rd|th)', '', floor_clean)\n    match = re.search(r'(-?\\d+(?:\\.\\d+)?)', floor_clean)\n    \n    if match:\n        return float(match.group(1))\n    \n    return np.nan\n\n# Apply cleaning\ndf['floor_number'] = df['floor'].apply(clean_floor)\n\nprint(\"\\nFloor statistics after cleaning:\")\nprint(df['floor_number'].describe())\n\nprint(f\"\\nMissing values in floor_number: {df['floor_number'].isnull().sum()}\")\n\n# Check distribution\nprint(\"\\nFloor distribution:\")\nprint(df['floor_number'].value_counts().sort_index().head(20))\n\n# ============================================================================\n# CELL 12: Clean Location Column\n# ============================================================================\nprint(\"=\"*80)\nprint(\"CLEANING: LOCATION\")\nprint(\"=\"*80)\n\nprint(\"\\nOriginal location samples:\")\nprint(df['location'].head(10))\n\n# Standardize location\ndf['location_clean'] = df['location'].str.strip()\n\n# Extract neighborhood (before the parenthesis)\ndf['neighborhood'] = df['location_clean'].str.extract(r'^([^(]+)')[0].str.strip()\n\n# Extract district (inside parenthesis if exists)\ndf['district'] = df['location_clean'].str.extract(r'\\(([^)]+)\\)')[0]\n\nprint(\"\\nLocation cleaning completed!\")\nprint(f\"\\nMissing values in location: {df['location_clean'].isnull().sum()}\")\nprint(f\"Missing values in neighborhood: {df['neighborhood'].isnull().sum()}\")\nprint(f\"Missing values in district: {df['district'].isnull().sum()}\")\n\nprint(\"\\nTop 10 neighborhoods:\")\nprint(df['neighborhood'].value_counts().head(10))\n\n# ============================================================================\n# CELL 13: Feature Engineering - Price per Square Meter\n# ============================================================================\nprint(\"=\"*80)\nprint(\"FEATURE ENGINEERING: PRICE PER SQUARE METER\")\nprint(\"=\"*80)\n\n# Calculate price per square meter\ndf['price_per_sqm'] = df['price_eur'] / df['size_sqm']\n\nprint(\"\\nPrice per sqm statistics:\")\nprint(df['price_per_sqm'].describe())\n\nprint(f\"\\nMissing values in price_per_sqm: {df['price_per_sqm'].isnull().sum()}\")\n\n# Check for unrealistic values\nprint(f\"\\nProperties with price/sqm < €100: {(df['price_per_sqm'] < 100).sum()}\")\nprint(f\"Properties with price/sqm > €10,000: {(df['price_per_sqm'] > 10000).sum()}\")\n\n# ============================================================================\n# CELL 14: Feature Engineering - Additional Features\n# ============================================================================\nprint(\"=\"*80)\nprint(\"FEATURE ENGINEERING: ADDITIONAL FEATURES\")\nprint(\"=\"*80)\n\n# Bathroom to bedroom ratio\ndf['bath_bed_ratio'] = df['bathrooms'] / df['bedrooms']\ndf['bath_bed_ratio'] = df['bath_bed_ratio'].replace([np.inf, -np.inf], np.nan)\n\n# Property size category\ndef categorize_size(size):\n    if pd.isna(size):\n        return 'Unknown'\n    elif size < 50:\n        return 'Small'\n    elif size < 100:\n        return 'Medium'\n    elif size < 200:\n        return 'Large'\n    else:\n        return 'Extra Large'\n\ndf['size_category'] = df['size_sqm'].apply(categorize_size)\n\n# Price category\ndef categorize_price(price):\n    if pd.isna(price):\n        return 'Unknown'\n    elif price < 100000:\n        return 'Budget'\n    elif price < 250000:\n        return 'Moderate'\n    elif price < 500000:\n        return 'Premium'\n    else:\n        return 'Luxury'\n\ndf['price_category'] = df['price_eur'].apply(categorize_price)\n\n# Floor category\ndef categorize_floor(floor):\n    if pd.isna(floor):\n        return 'Unknown'\n    elif floor < 0:\n        return 'Basement/Semi-basement'\n    elif floor == 0:\n        return 'Ground Floor'\n    elif floor <= 2:\n        return 'Low Floor'\n    elif floor <= 5:\n        return 'Mid Floor'\n    else:\n        return 'High Floor'\n\ndf['floor_category'] = df['floor_number'].apply(categorize_floor)\n\nprint(\"Additional features created:\")\nprint(\"- bath_bed_ratio\")\nprint(\"- size_category\")\nprint(\"- price_category\")\nprint(\"- floor_category\")\n\nprint(\"\\nSize category distribution:\")\nprint(df['size_category'].value_counts())\n\nprint(\"\\nPrice category distribution:\")\nprint(df['price_category'].value_counts())\n\nprint(\"\\nFloor category distribution:\")\nprint(df['floor_category'].value_counts())\n\n# ============================================================================\n# CELL 15: Handle Missing Values - Analysis\n# ============================================================================\nprint(\"=\"*80)\nprint(\"MISSING VALUES ANALYSIS AFTER CLEANING\")\nprint(\"=\"*80)\n\n# Check missing values in cleaned columns\ncleaned_cols = ['property_type', 'size_sqm', 'price_eur', 'bedrooms', 'bathrooms', \n                'floor_number', 'location_clean', 'neighborhood', 'price_per_sqm']\n\nmissing_after = pd.DataFrame({\n    'Column': cleaned_cols,\n    'Missing_Count': [df[col].isnull().sum() for col in cleaned_cols],\n    'Missing_Percentage': [(df[col].isnull().sum() / len(df) * 100).round(2) for col in cleaned_cols]\n})\nmissing_after = missing_after[missing_after['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n\nprint(\"\\nMissing Values in Cleaned Columns:\")\nif len(missing_after) > 0:\n    print(missing_after.to_string(index=False))\nelse:\n    print(\"No missing values in cleaned columns!\")\n\n# Visualize missing values\nfig, ax = plt.subplots(1, 2, figsize=(15, 6))\n\n# Before cleaning\nmissing_before = df_raw.isnull().sum()\nmissing_before[missing_before > 0].plot(kind='bar', ax=ax[0], color='coral')\nax[0].set_title('Missing Values - Original Data', fontsize=12, fontweight='bold')\nax[0].set_xlabel('Columns')\nax[0].set_ylabel('Count')\nax[0].tick_params(axis='x', rotation=45)\n\n# After cleaning\nmissing_after_all = df[cleaned_cols].isnull().sum()\nmissing_after_all[missing_after_all > 0].plot(kind='bar', ax=ax[1], color='lightblue')\nax[1].set_title('Missing Values - Cleaned Data', fontsize=12, fontweight='bold')\nax[1].set_xlabel('Columns')\nax[1].set_ylabel('Count')\nax[1].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# CELL 16: Handle Missing Values - Imputation Strategy\n# ============================================================================\nprint(\"=\"*80)\nprint(\"MISSING VALUES - IMPUTATION STRATEGY\")\nprint(\"=\"*80)\n\n# Create a copy before imputation\ndf_before_imputation = df.copy()\n\n# Strategy for numerical columns with missing values\nprint(\"\\nImputation strategy:\")\nprint(\"- bedrooms: Fill with median (most common approach for count data)\")\nprint(\"- bathrooms: Fill with median\")\nprint(\"- floor_number: Fill with median\")\nprint(\"- size_sqm: Keep as NaN or drop rows (critical feature)\")\nprint(\"- price_eur: Keep as NaN or drop rows (critical feature - target variable)\")\n\n# Fill bedrooms with median\nif df['bedrooms'].isnull().sum() > 0:\n    median_bedrooms = df['bedrooms'].median()\n    df['bedrooms'].fillna(median_bedrooms, inplace=True)\n    print(f\"\\nFilled {df_before_imputation['bedrooms'].isnull().sum()} missing bedrooms with median: {median_bedrooms}\")\n\n# Fill bathrooms with median\nif df['bathrooms'].isnull().sum() > 0:\n    median_bathrooms = df['bathrooms'].median()\n    df['bathrooms'].fillna(median_bathrooms, inplace=True)\n    print(f\"Filled {df_before_imputation['bathrooms'].isnull().sum()} missing bathrooms with median: {median_bathrooms}\")\n\n# Fill floor_number with median\nif df['floor_number'].isnull().sum() > 0:\n    median_floor = df['floor_number'].median()\n    df['floor_number'].fillna(median_floor, inplace=True)\n    print(f\"Filled {df_before_imputation['floor_number'].isnull().sum()} missing floor_number with median: {median_floor}\")\n\n# For critical features (price, size), we'll analyze if we should drop or keep\nprint(f\"\\nCritical features with missing values:\")\nprint(f\"- price_eur: {df['price_eur'].isnull().sum()} missing ({(df['price_eur'].isnull().sum()/len(df)*100):.2f}%)\")\nprint(f\"- size_sqm: {df['size_sqm'].isnull().sum()} missing ({(df['size_sqm'].isnull().sum()/len(df)*100):.2f}%)\")\n\n# ============================================================================\n# CELL 17: Outlier Detection and Analysis\n# ============================================================================\nprint(\"=\"*80)\nprint(\"OUTLIER DETECTION AND ANALYSIS\")\nprint(\"=\"*80)\n\n# Function to detect outliers using IQR method\ndef detect_outliers_iqr(data, column):\n    Q1 = data[column].quantile(0.25)\n    Q3 = data[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n    return outliers, lower_bound, upper_bound\n\n# Analyze outliers for numerical columns\nnumerical_cols = ['size_sqm', 'price_eur', 'bedrooms', 'bathrooms', 'floor_number', 'price_per_sqm']\n\noutlier_summary = []\nfor col in numerical_cols:\n    if col in df.columns:\n        outliers, lower, upper = detect_outliers_iqr(df, col)\n        outlier_summary.append({\n            'Column': col,\n            'Outlier_Count': len(outliers),\n            'Outlier_Percentage': f\"{(len(outliers)/len(df)*100):.2f}%\",\n            'Lower_Bound': f\"{lower:.2f}\",\n            'Upper_Bound': f\"{upper:.2f}\"\n        })\n\noutlier_df = pd.DataFrame(outlier_summary)\nprint(\"\\nOutlier Summary (IQR Method):\")\nprint(outlier_df.to_string(index=False))\n\n# Visualize outliers with boxplots\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes = axes.ravel()\n\nfor idx, col in enumerate(numerical_cols):\n    if col in df.columns:\n        df.boxplot(column=col, ax=axes[idx])\n        axes[idx].set_title(f'{col}', fontsize=12, fontweight='bold')\n        axes[idx].set_ylabel('Value')\n\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# CELL 18: Outlier Treatment\n# ============================================================================\nprint(\"=\"*80)\nprint(\"OUTLIER TREATMENT\")\nprint(\"=\"*80)\n\nprint(\"\\nOutlier treatment strategy:\")\nprint(\"We will use a combination of:\")\nprint(\"1. Domain knowledge to identify truly unrealistic values\")\nprint(\"2. Statistical methods (IQR) with careful consideration\")\nprint(\"3. Capping extreme values rather than removing (when appropriate)\")\n\n# Create a copy before outlier treatment\ndf_before_outlier = df.copy()\ninitial_count = len(df)\n\n# Remove unrealistic values based on domain knowledge\nprint(\"\\nRemoving unrealistic values:\")\n\n# Size: Properties smaller than 15 m² or larger than 2000 m² are likely errors\nif 'size_sqm' in df.columns:\n    size_outliers = df[(df['size_sqm'] < 15) | (df['size_sqm'] > 2000)].shape[0]\n    df = df[(df['size_sqm'].isna()) | ((df['size_sqm'] >= 15) & (df['size_sqm'] <= 2000))]\n    print(f\"- Removed {size_outliers} properties with size < 15 m² or > 2000 m²\")\n\n# Price: Properties cheaper than €10,000 or more expensive than €10,000,000 are likely errors\nif 'price_eur' in df.columns:\n    price_outliers = df[(df['price_eur'] < 10000) | (df['price_eur'] > 10000000)].shape[0]\n    df = df[(df['price_eur'].isna()) | ((df['price_eur'] >= 10000) & (df['price_eur'] <= 10000000))]\n    print(f\"- Removed {price_outliers} properties with price < €10,000 or > €10,000,000\")\n\n# Bedrooms: More than 15 bedrooms is unrealistic for residential property\nif 'bedrooms' in df.columns:\n    bedroom_outliers = df[df['bedrooms'] > 15].shape[0]\n    df = df[(df['bedrooms'].isna()) | (df['bedrooms'] <= 15)]\n    print(f\"- Removed {bedroom_outliers} properties with > 15 bedrooms\")\n\n# Bathrooms: More than 15 bathrooms is unrealistic\nif 'bathrooms' in df.columns:\n    bathroom_outliers = df[df['bathrooms'] > 15].shape[0]\n    df = df[(df['bathrooms'].isna()) | (df['bathrooms'] <= 15)]\n    print(f\"- Removed {bathroom_outliers} properties with > 15 bathrooms\")\n\n# Floor: Buildings higher than 50 floors are rare in Athens\nif 'floor_number' in df.columns:\n    floor_outliers = df[(df['floor_number'] < -2) | (df['floor_number'] > 50)].shape[0]\n    df = df[(df['floor_number'].isna()) | ((df['floor_number'] >= -2) & (df['floor_number'] <= 50))]\n    print(f\"- Removed {floor_outliers} properties with floor < -2 or > 50\")\n\n# Price per sqm: Should be within reasonable range (€500 - €15,000)\nif 'price_per_sqm' in df.columns:\n    ppsqm_outliers = df[(df['price_per_sqm'] < 500) | (df['price_per_sqm'] > 15000)].shape[0]\n    df = df[(df['price_per_sqm'].isna()) | ((df['price_per_sqm'] >= 500) & (df['price_per_sqm'] <= 15000))]\n    print(f\"- Removed {ppsqm_outliers} properties with price/sqm < €500 or > €15,000\")\n\nprint(f\"\\nTotal rows removed: {initial_count - len(df)}\")\nprint(f\"Remaining rows: {len(df)}\")\nprint(f\"Percentage retained: {(len(df)/initial_count*100):.2f}%\")\n\n# Reset index\ndf.reset_index(drop=True, inplace=True)\n\n# ============================================================================\n# CELL 19: Data Consistency Checks\n# ============================================================================\nprint(\"=\"*80)\nprint(\"DATA CONSISTENCY CHECKS\")\nprint(\"=\"*80)\n\n# Check logical relationships\nprint(\"\\nChecking logical relationships:\")\n\n# 1. Bathrooms should not exceed bedrooms by too much\nif 'bathrooms' in df.columns and 'bedrooms' in df.columns:\n    unusual_bath_bed = df[df['bathrooms'] > df['bedrooms'] * 2]\n    print(f\"- Properties with bathrooms > 2x bedrooms: {len(unusual_bath_bed)}\")\n\n# 2. Price should correlate with size (check extreme deviations)\nif 'price_per_sqm' in df.columns:\n    price_per_sqm_stats = df['price_per_sqm'].describe()\n    print(f\"\\n- Price per sqm range: €{price_per_sqm_stats['min']:.2f} - €{price_per_sqm_stats['max']:.2f}\")\n    print(f\"- Price per sqm mean: €{price_per_sqm_stats['mean']:.2f}\")\n    print(f\"- Price per sqm median: €{price_per_sqm_stats['50%']:.2f}\")\n\n# 3. Buildings should have reasonable floor counts for property type\nprint(\"\\n- Checking floor distribution by property type:\")\nif 'property_type' in df.columns and 'floor_number' in df.columns:\n    floor_by_type = df.groupby('property_type')['floor_number'].describe()\n    print(floor_by_type[['count', 'mean', 'min', 'max']])\n\n# ============================================================================\n# CELL 20: Final Data Quality Report\n# ============================================================================\nprint(\"=\"*80)\nprint(\"FINAL DATA QUALITY REPORT\")\nprint(\"=\"*80)\n\nprint(f\"\\nOriginal dataset: {df_raw.shape[0]} rows, {df_raw.shape[1]} columns\")\nprint(f\"Cleaned dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\nprint(f\"Rows removed: {df_raw.shape[0] - df.shape[0]} ({((df_raw.shape[0] - df.shape[0])/df_raw.shape[0]*100):.2f}%)\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"CLEANING SUMMARY\")\nprint(\"=\"*80)\n\ncleaning_summary = {\n    'Task': [\n        'Duplicate Removal',\n        'Size Cleaning',\n        'Price Cleaning',\n        'Floor Standardization',\n        'Location Parsing',\n        'Missing Value Imputation',\n        'Outlier Removal',\n        'Feature Engineering'\n    ],\n    'Status': ['✓'] * 8,\n    'Details': [\n        f'Removed duplicates based on URL',\n        'Extracted numeric values from \"m²\" format',\n        'Extracted numeric values from \"€X,XXX\" format',\n        'Standardized floor notation (G, 1st, 2nd, etc.)',\n        'Split into neighborhood and district',\n        'Filled bedrooms, bathrooms, floor with median',\n        'Removed unrealistic values using domain knowledge',\n        'Created price_per_sqm, size_category, price_category, floor_category'\n    ]\n}\n\nsummary_df = pd.DataFrame(cleaning_summary)\nprint(summary_df.to_string(index=False))\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL DATASET CHARACTERISTICS\")\nprint(\"=\"*80)\n\n# Count complete cases\ncomplete_cases = df.dropna(subset=['price_eur', 'size_sqm', 'bedrooms', 'bathrooms', 'floor_number'])\nprint(f\"\\nComplete cases (no missing values in key features): {len(complete_cases)}\")\nprint(f\"Percentage of complete cases: {(len(complete_cases)/len(df)*100):.2f}%\")\n\nprint(\"\\nFinal missing values:\")\nfinal_missing = df[['property_type', 'size_sqm', 'price_eur', 'bedrooms', \n                     'bathrooms', 'floor_number', 'neighborhood']].isnull().sum()\nprint(final_missing[final_missing > 0])\n\nprint(\"\\nData types in final dataset:\")\nprint(df.dtypes)\n\n# ============================================================================\n# CELL 21: Select Final Columns for Clean Dataset\n# ============================================================================\nprint(\"=\"*80)\nprint(\"SELECTING FINAL COLUMNS\")\nprint(\"=\"*","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}